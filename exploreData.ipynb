{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:23.004399Z",
     "start_time": "2021-07-24T17:16:33.867507Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import sklearn.metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:26.737360Z",
     "start_time": "2021-07-24T17:17:26.057668Z"
    }
   },
   "outputs": [],
   "source": [
    "datasheet_df = pd.read_csv('Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = datasheet_df.isnull().sum() * 100 / len(datasheet_df)\n",
    "missing_value_df = pd.DataFrame({'column_name': datasheet_df.columns,\n",
    "                                 'percent_missing': percent_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:26.820153Z",
     "start_time": "2021-07-24T17:17:26.766386Z"
    }
   },
   "outputs": [],
   "source": [
    "class_balance = Counter(datasheet_df.becameLicensed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:26.824641Z",
     "start_time": "2021-07-24T17:17:26.821531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Licensed Users: 95.34%\n"
     ]
    }
   ],
   "source": [
    "print('Non Licensed Users: '+str(round(class_balance[0]*100/(class_balance[0]+class_balance[1]),2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:26.991208Z",
     "start_time": "2021-07-24T17:17:26.987392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Licensed Users: 4.66%\n"
     ]
    }
   ],
   "source": [
    "print('Licensed Users: '+str(round(class_balance[1]*100/(class_balance[0]+class_balance[1]),2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T16:20:37.275755Z",
     "start_time": "2021-07-24T16:20:37.273782Z"
    }
   },
   "source": [
    "Problems:\n",
    "1. Class Imbalance: 95% Non Licensed Users and 5% Licensed Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:27.622210Z",
     "start_time": "2021-07-24T17:17:27.462448Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = datasheet_df.loc[:,~datasheet_df.columns.isin(['becameLicensed'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-24T17:17:27.748125Z",
     "start_time": "2021-07-24T17:17:27.740165Z"
    }
   },
   "outputs": [],
   "source": [
    "output_data = datasheet_df[['becameLicensed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage datapoints that are outliers is 0%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 11%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 2%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 1%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 5%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 9%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 8%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 5%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 11%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 3%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 3%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 1%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 16%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 11%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n",
      "Percentage datapoints that are outliers is 18%\n",
      "Percentage datapoints that are outliers is 0.0%\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in input_data.columns:\n",
    "    if col not in categorical_value_candidate:\n",
    "        \n",
    "        q_1 = input_data[col].describe()['25%']\n",
    "        q_3 = input_data[col].describe()['75%']\n",
    "        inter_quartile_range =  round(q_3 - q_1,2)\n",
    "        upper_limit_outlier = round(q_3 + 1.5*inter_quartile_range,2)\n",
    "        lower_limit_outlier = round(q_1 - 1.5*inter_quartile_range,2)\n",
    "        \n",
    "        outlier_count = 0\n",
    "        lower_outliers, upper_outliers = 0,0\n",
    "        for i in input_data[col]:\n",
    "            if i > upper_limit_outlier:\n",
    "                upper_outliers+=1 \n",
    "                outlier_count+=1\n",
    "            if i < lower_limit_outlier:\n",
    "                lower_outliers+=1\n",
    "                outlier_count+=1\n",
    "        print(\"Percentage datapoints that are outliers is \"+str(round(outlier_count*100/len(input_data[col])))+\"%\")\n",
    "\n",
    "        valid_upper_val = input_data[input_data[col] < upper_limit_outlier][col].max()\n",
    "        valid_lower_val = input_data[input_data[col] > lower_limit_outlier][col].min()\n",
    "        \n",
    "        input_data.loc[input_data[col]>upper_limit_outlier,col]=valid_upper_val\n",
    "        input_data.loc[input_data[col]<lower_limit_outlier,col]=valid_lower_val\n",
    "        \n",
    "        outlier_count = 0\n",
    "        lower_outliers, upper_outliers = 0,0\n",
    "        for i in input_data[col]:\n",
    "            if i > upper_limit_outlier:\n",
    "                upper_outliers+=1 \n",
    "                outlier_count+=1\n",
    "            if i < lower_limit_outlier:\n",
    "                lower_outliers+=1\n",
    "                outlier_count+=1\n",
    "        print(\"Percentage datapoints that are outliers is \"+str(outlier_count*100/len(input_data[col]))+\"%\")\n",
    "        \n",
    "        print('\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding of Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in categorical_value_candidate:\n",
    "    input_data = pd.concat([input_data, pd.get_dummies(input_data[var]).add_prefix(var)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479229, 1271)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
